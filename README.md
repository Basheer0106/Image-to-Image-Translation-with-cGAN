# Image-to-Image-Translation-with-cGAN
This project uses a Conditional GAN (cGAN) to translate input images into corresponding output images by learning paired image mappings, enabling realistic and structure-preserving transformations.
# Image-to-Image Translation with cGAN (pix2pix)

## Overview
This project implements **image-to-image translation using a Conditional Generative Adversarial Network (cGAN)** based on the **pix2pix** architecture. The model learns a mapping from an input image to an output image using paired training data.

The approach uses a generator to produce translated images and a discriminator to evaluate their realism, enabling the model to generate high-quality and visually consistent outputs.

---

## Features
- Image-to-image translation using Conditional GANs
- Pix2pix architecture implementation
- Trains on paired inputâ€“output images
- Generates realistic translated images
- Demonstrates adversarial training concepts

---

## Tools & Technologies
- Python
- TensorFlow / PyTorch
- Conditional GAN (cGAN)
- Pix2pix
- Computer Vision
- Google Colab

---

## Execution
The project was developed and executed using **Google Colab**, enabling efficient training with GPU acceleration.

---

## Output
The model generates translated images that preserve the structure of the input image while adapting it to the target domain.

---

## Learning Outcomes
- Understanding Conditional GANs
- Hands-on experience with pix2pix
- Knowledge of adversarial training for image translation
- Practical exposure to image-to-image translation tasks
